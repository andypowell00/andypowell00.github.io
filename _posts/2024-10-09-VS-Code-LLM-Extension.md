---
layout: post
title:  "Setting Up the Continue VS Code Extension with Ollama"
date:   2023-10-09 16:21:59 -0400
categories: development tools
tags: vscode ollama starcoder llama ai-autocomplete
---

### Integrating the Continue VS Code Extension with Ollama for Enhanced AI Assistance

Boosting your development workflow with AI tools can significantly improve productivity. This guide walks through setting up the **Continue** VS Code extension using Ollama to run AI models like Starcoder (for code autocomplete) and Llama (for chat functionality). Here's how you can get started on Windows or Linux.

#### Step 1: Install Ollama
1. Visit the [Ollama website](https://ollama.ai) and download the installer for your platform (Windows or Linux).
2. Follow the installation instructions to set up Ollama on your system.

#### Step 2: Download Models
1. Open Ollama and download the necessary models:
   - **Starcoder**: Ideal for AI-driven code autocomplete.
   - **Llama**: A robust chat model for conversational assistance.
2. Confirm the models are available and running correctly within Ollama.

#### Step 3: Install the Continue Extension in VS Code
1. Open Visual Studio Code.
2. Navigate to the **Extensions** view (`Ctrl+Shift+X` or `Cmd+Shift+X` on Mac).
3. Search for **Continue** and install the extension.

#### Step 4: Connect Continue to Ollama
1. Open the Continue extension settings in VS Code.
2. Configure the connection to point to the Ollama instance running locally on your machine.
3. Specify the paths to the downloaded models (Starcoder and Llama) if required.

#### Step 5: Test Your Setup
1. Restart VS Code to apply changes.
2. Open a coding project and test the Starcoder model for code suggestions and completions.
3. Use the Llama chat model within the Continue extension for conversational help or queries.

### Conclusion

By integrating Ollama with the Continue VS Code extension, you unlock powerful AI capabilities for your development environment. Whether you're seeking smarter autocompletion with Starcoder or conversational insights through Llama, this setup enhances efficiency and brings cutting-edge tools to your fingertips.

For troubleshooting or advanced configurations, refer to the official documentation for Ollama and the Continue extension. Happy coding!
